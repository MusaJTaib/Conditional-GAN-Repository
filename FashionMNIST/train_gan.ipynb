{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LOAD DATA\n",
    "\n",
    "sample_count = 9000\n",
    "\n",
    "X_dev = np.load(f\"data/base_data/MNIST_X_dev_{sample_count}_data.npy\")\n",
    "y_dev = np.load(f\"data/base_data/MNIST_y_dev_{sample_count}_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (9000, 28, 28, 1)\n",
      "Shape of training labels: (9000, 10)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_channels = 1\n",
    "num_classes = 10\n",
    "image_size = 28\n",
    "latent_dim = 128\n",
    "\n",
    "\n",
    "# Scale the pixel values to [0, 1] range, add a channel dimension to\n",
    "# the images, and one-hot encode the labels.\n",
    "all_images = X_dev.astype(\"float32\") / 255.0\n",
    "all_images = np.reshape(all_images, (-1, 28, 28, 1))\n",
    "all_labels = tf.keras.utils.to_categorical(y_dev, 10)\n",
    "\n",
    "\n",
    "# Create tf.data.Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_images, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "print(f\"Shape of training images: {all_images.shape}\")\n",
    "print(f\"Shape of training labels: {all_labels.shape}\")\n",
    "\n",
    "\n",
    "generator_in_channels = latent_dim\n",
    "discriminator_in_channels = num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(dim = 7,  dropout = 0.25, kshape = (5,5)):\n",
    "\n",
    "    #label input\n",
    "    label_input = tf.keras.layers.Input((num_classes))\n",
    "    label_dense = tf.keras.layers.Dense(dim*dim*1, activation=tf.keras.layers.LeakyReLU(alpha=0.2))(label_input)\n",
    "    label_reshape = tf.keras.layers.Reshape((7,7,1))(label_dense)\n",
    "\n",
    "    random_input = tf.keras.layers.Input(generator_in_channels)\n",
    "    x1 = tf.keras.layers.Dense(dim*dim*generator_in_channels, activation=tf.keras.layers.LeakyReLU(alpha=0.2))(random_input)\n",
    "    x2 = tf.keras.layers.Reshape((7,7,generator_in_channels))(x1)\n",
    "\n",
    "    #concat the layers\n",
    "    x3 = tf.keras.layers.Concatenate()([x2,label_reshape])\n",
    "\n",
    "    x4 = tf.keras.layers.Conv2DTranspose(256,(4,4),strides=(2,2),activation=tf.keras.layers.LeakyReLU(alpha=0.2),padding=\"same\")(x3)\n",
    "    x5 = tf.keras.layers.Conv2DTranspose(128,(4,4),strides=(2,2),activation=tf.keras.layers.LeakyReLU(alpha=0.2),padding=\"same\")(x4)\n",
    "    x6 = tf.keras.layers.Conv2D(1,(7,7),padding=\"same\",activation=\"sigmoid\")(x5)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[random_input,label_input], outputs=x6)\n",
    "    return model\n",
    "\n",
    "generator_model = generator()\n",
    "#print(generator_model.summary())\n",
    "\n",
    "\n",
    "def discriminator(dim=7):\n",
    "    #label input\n",
    "    label_input = tf.keras.layers.Input((num_classes))\n",
    "    label_dense = tf.keras.layers.Dense(dim*dim*2*2, activation=tf.keras.layers.LeakyReLU(alpha=0.2))(label_input)\n",
    "    label_reshape = tf.keras.layers.Reshape((14,14,1))(label_dense)\n",
    "\n",
    "    #input image\n",
    "    x1 = tf.keras.layers.Input((image_size,image_size,1))\n",
    "    x2 = tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2),activation=tf.keras.layers.LeakyReLU(alpha=0.2), padding=\"same\")(x1)\n",
    "\n",
    "    x3 = tf.keras.layers.Concatenate()([x2,label_reshape])\n",
    "    x4 = tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2),activation=tf.keras.layers.LeakyReLU(alpha=0.2), padding=\"same\")(x3)\n",
    "    globalmaxpool = tf.keras.layers.GlobalMaxPooling2D()(x4)\n",
    "    final_layer = tf.keras.layers.Dense(1,activation=\"sigmoid\")(globalmaxpool)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[x1,label_input], outputs=final_layer)\n",
    "    return model\n",
    "\n",
    "discriminator_model = discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGAN(tf.keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = tf.keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = tf.keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        fake_images = self.generator([random_latent_vectors,one_hot_labels])\n",
    "        fake_labels = one_hot_labels\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        all_images = tf.concat([fake_images,real_images],axis=0)\n",
    "        all_labels = tf.concat([one_hot_labels,one_hot_labels],axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator([all_images,all_labels])\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size*2, self.latent_dim))\n",
    "\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size*2, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator([random_latent_vectors,all_labels])\n",
    "            #fake_labels = tf.concat([one_hot_labels,one_hot_labels],axis=0)\n",
    "            predictions = self.discriminator([fake_images,all_labels])\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator_model, generator=generator_model, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=tf.keras.optimizers.RMSprop(lr = 0.0008, clipvalue = 1.0, decay = 6e-8),\n",
    "    g_optimizer=tf.keras.optimizers.RMSprop(lr = 0.0004, clipvalue = 1.0, decay = 3e-8),\n",
    "    loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 6s 47ms/step - g_loss: 0.9374 - d_loss: 0.4836\n",
      "Epoch 2/200\n",
      "71/71 [==============================] - 3s 43ms/step - g_loss: 1.1665 - d_loss: 0.4753\n",
      "Epoch 3/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0207 - d_loss: 0.5635\n",
      "Epoch 4/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 0.9245 - d_loss: 0.5966\n",
      "Epoch 5/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 0.9403 - d_loss: 0.5967\n",
      "Epoch 6/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 0.9734 - d_loss: 0.5476\n",
      "Epoch 7/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0739 - d_loss: 0.5086\n",
      "Epoch 8/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.1848 - d_loss: 0.4648\n",
      "Epoch 9/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.2584 - d_loss: 0.4471\n",
      "Epoch 10/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.2909 - d_loss: 0.4416\n",
      "Epoch 11/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.3086 - d_loss: 0.4407\n",
      "Epoch 12/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.2725 - d_loss: 0.4510\n",
      "Epoch 13/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.2785 - d_loss: 0.4493\n",
      "Epoch 14/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.2693 - d_loss: 0.4490\n",
      "Epoch 15/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.2720 - d_loss: 0.4696\n",
      "Epoch 16/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.2166 - d_loss: 0.4947\n",
      "Epoch 17/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.1295 - d_loss: 0.5117\n",
      "Epoch 18/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.1312 - d_loss: 0.5153\n",
      "Epoch 19/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0656 - d_loss: 0.5385\n",
      "Epoch 20/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0852 - d_loss: 0.5432\n",
      "Epoch 21/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0490 - d_loss: 0.5440\n",
      "Epoch 22/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0821 - d_loss: 0.5325\n",
      "Epoch 23/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0472 - d_loss: 0.5455\n",
      "Epoch 24/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0459 - d_loss: 0.5589\n",
      "Epoch 25/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0102 - d_loss: 0.5703\n",
      "Epoch 26/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0284 - d_loss: 0.5656\n",
      "Epoch 27/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0087 - d_loss: 0.5616\n",
      "Epoch 28/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0120 - d_loss: 0.5570\n",
      "Epoch 29/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0060 - d_loss: 0.5691\n",
      "Epoch 30/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0223 - d_loss: 0.5642\n",
      "Epoch 31/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0059 - d_loss: 0.5643\n",
      "Epoch 32/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0293 - d_loss: 0.5684\n",
      "Epoch 33/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0080 - d_loss: 0.5726\n",
      "Epoch 34/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 1.0273 - d_loss: 0.5735\n",
      "Epoch 35/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 0.9992 - d_loss: 0.5728\n",
      "Epoch 36/200\n",
      "71/71 [==============================] - 3s 44ms/step - g_loss: 1.0065 - d_loss: 0.5668\n",
      "Epoch 37/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9969 - d_loss: 0.5675\n",
      "Epoch 38/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 1.0205 - d_loss: 0.5680\n",
      "Epoch 39/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 1.0083 - d_loss: 0.5671\n",
      "Epoch 40/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 1.0160 - d_loss: 0.5658\n",
      "Epoch 41/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9923 - d_loss: 0.5710\n",
      "Epoch 42/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 1.0202 - d_loss: 0.5827\n",
      "Epoch 43/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9836 - d_loss: 0.5879\n",
      "Epoch 44/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9890 - d_loss: 0.5900\n",
      "Epoch 45/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9629 - d_loss: 0.5919\n",
      "Epoch 46/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9815 - d_loss: 0.5953\n",
      "Epoch 47/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9527 - d_loss: 0.5956\n",
      "Epoch 48/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9668 - d_loss: 0.5922\n",
      "Epoch 49/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9559 - d_loss: 0.6003\n",
      "Epoch 50/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9630 - d_loss: 0.5988\n",
      "Epoch 51/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9426 - d_loss: 0.5987\n",
      "Epoch 52/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9605 - d_loss: 0.5990\n",
      "Epoch 53/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9284 - d_loss: 0.6112\n",
      "Epoch 54/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9497 - d_loss: 0.6047\n",
      "Epoch 55/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9306 - d_loss: 0.6009\n",
      "Epoch 56/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9451 - d_loss: 0.6069\n",
      "Epoch 57/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9335 - d_loss: 0.6085\n",
      "Epoch 58/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9391 - d_loss: 0.6118\n",
      "Epoch 59/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9122 - d_loss: 0.6113\n",
      "Epoch 60/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9370 - d_loss: 0.6092\n",
      "Epoch 61/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9177 - d_loss: 0.6057\n",
      "Epoch 62/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9406 - d_loss: 0.6053\n",
      "Epoch 63/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9228 - d_loss: 0.6029\n",
      "Epoch 64/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9482 - d_loss: 0.6095\n",
      "Epoch 65/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9311 - d_loss: 0.6003\n",
      "Epoch 66/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9242 - d_loss: 0.6050\n",
      "Epoch 67/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9399 - d_loss: 0.6071\n",
      "Epoch 68/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9273 - d_loss: 0.6055\n",
      "Epoch 69/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9354 - d_loss: 0.6027\n",
      "Epoch 70/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9132 - d_loss: 0.6096\n",
      "Epoch 71/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9272 - d_loss: 0.6100\n",
      "Epoch 72/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9168 - d_loss: 0.6152\n",
      "Epoch 73/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9381 - d_loss: 0.6109\n",
      "Epoch 74/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9116 - d_loss: 0.6083\n",
      "Epoch 75/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9319 - d_loss: 0.6126\n",
      "Epoch 76/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9147 - d_loss: 0.6086\n",
      "Epoch 77/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9480 - d_loss: 0.6086\n",
      "Epoch 78/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9138 - d_loss: 0.6038\n",
      "Epoch 79/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9432 - d_loss: 0.6080\n",
      "Epoch 80/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9200 - d_loss: 0.6083\n",
      "Epoch 81/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9390 - d_loss: 0.6008\n",
      "Epoch 82/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9190 - d_loss: 0.6052\n",
      "Epoch 83/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9434 - d_loss: 0.6043\n",
      "Epoch 84/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9236 - d_loss: 0.6029\n",
      "Epoch 85/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9413 - d_loss: 0.6063\n",
      "Epoch 86/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9229 - d_loss: 0.6078\n",
      "Epoch 87/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 0.9479 - d_loss: 0.6086\n",
      "Epoch 88/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 0.9202 - d_loss: 0.6070\n",
      "Epoch 89/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9414 - d_loss: 0.6047\n",
      "Epoch 90/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9250 - d_loss: 0.6061\n",
      "Epoch 91/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 0.9423 - d_loss: 0.6066\n",
      "Epoch 92/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9167 - d_loss: 0.6039\n",
      "Epoch 93/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9437 - d_loss: 0.6055\n",
      "Epoch 94/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 0.9204 - d_loss: 0.6085\n",
      "Epoch 95/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9335 - d_loss: 0.5996\n",
      "Epoch 96/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9321 - d_loss: 0.6036\n",
      "Epoch 97/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9565 - d_loss: 0.6047\n",
      "Epoch 98/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9242 - d_loss: 0.6023\n",
      "Epoch 99/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9491 - d_loss: 0.6001\n",
      "Epoch 100/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9357 - d_loss: 0.6008\n",
      "Epoch 101/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9683 - d_loss: 0.6055\n",
      "Epoch 102/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9338 - d_loss: 0.6023\n",
      "Epoch 103/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9531 - d_loss: 0.5979\n",
      "Epoch 104/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9294 - d_loss: 0.6024\n",
      "Epoch 105/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9540 - d_loss: 0.6002\n",
      "Epoch 106/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9324 - d_loss: 0.5976\n",
      "Epoch 107/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9512 - d_loss: 0.5981\n",
      "Epoch 108/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9388 - d_loss: 0.5984\n",
      "Epoch 109/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9727 - d_loss: 0.6069\n",
      "Epoch 110/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9354 - d_loss: 0.5982\n",
      "Epoch 111/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9647 - d_loss: 0.6018\n",
      "Epoch 112/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9490 - d_loss: 0.6002\n",
      "Epoch 113/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9675 - d_loss: 0.5983\n",
      "Epoch 114/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9536 - d_loss: 0.6032\n",
      "Epoch 115/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9681 - d_loss: 0.5977\n",
      "Epoch 116/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9487 - d_loss: 0.5949\n",
      "Epoch 117/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9743 - d_loss: 0.5974\n",
      "Epoch 118/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9411 - d_loss: 0.5979\n",
      "Epoch 119/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9678 - d_loss: 0.5942\n",
      "Epoch 120/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9424 - d_loss: 0.5957\n",
      "Epoch 121/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9756 - d_loss: 0.5997\n",
      "Epoch 122/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9507 - d_loss: 0.5976\n",
      "Epoch 123/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9661 - d_loss: 0.5913\n",
      "Epoch 124/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9469 - d_loss: 0.5949\n",
      "Epoch 125/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9723 - d_loss: 0.5944\n",
      "Epoch 126/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9587 - d_loss: 0.5936\n",
      "Epoch 127/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9787 - d_loss: 0.5918\n",
      "Epoch 128/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9595 - d_loss: 0.5938\n",
      "Epoch 129/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9833 - d_loss: 0.5904\n",
      "Epoch 130/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9604 - d_loss: 0.5959\n",
      "Epoch 131/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 1.0011 - d_loss: 0.5967\n",
      "Epoch 132/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9638 - d_loss: 0.5879\n",
      "Epoch 133/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9888 - d_loss: 0.5865\n",
      "Epoch 134/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9653 - d_loss: 0.5862\n",
      "Epoch 135/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9945 - d_loss: 0.5875\n",
      "Epoch 136/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9716 - d_loss: 0.5870\n",
      "Epoch 137/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 1.0078 - d_loss: 0.5895\n",
      "Epoch 138/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9786 - d_loss: 0.5841\n",
      "Epoch 139/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9963 - d_loss: 0.5826\n",
      "Epoch 140/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9759 - d_loss: 0.5823\n",
      "Epoch 141/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 1.0030 - d_loss: 0.5833\n",
      "Epoch 142/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9767 - d_loss: 0.5894\n",
      "Epoch 143/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 1.0186 - d_loss: 0.5896\n",
      "Epoch 144/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 0.9800 - d_loss: 0.5805\n",
      "Epoch 145/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 1.0163 - d_loss: 0.5841\n",
      "Epoch 146/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9872 - d_loss: 0.5794\n",
      "Epoch 147/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 1.0154 - d_loss: 0.5901\n",
      "Epoch 148/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9878 - d_loss: 0.5781\n",
      "Epoch 149/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 1.0206 - d_loss: 0.5811\n",
      "Epoch 150/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9846 - d_loss: 0.5815\n",
      "Epoch 151/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 1.0132 - d_loss: 0.5798\n",
      "Epoch 152/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 0.9851 - d_loss: 0.5840\n",
      "Epoch 153/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 1.0024 - d_loss: 0.5812\n",
      "Epoch 154/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 0.9865 - d_loss: 0.5826\n",
      "Epoch 155/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0171 - d_loss: 0.5846\n",
      "Epoch 156/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0005 - d_loss: 0.5831\n",
      "Epoch 157/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0153 - d_loss: 0.5828\n",
      "Epoch 158/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 0.9918 - d_loss: 0.5860\n",
      "Epoch 159/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0204 - d_loss: 0.5790\n",
      "Epoch 160/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 0.9934 - d_loss: 0.5815\n",
      "Epoch 161/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0146 - d_loss: 0.5780\n",
      "Epoch 162/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0087 - d_loss: 0.5805\n",
      "Epoch 163/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0210 - d_loss: 0.5737\n",
      "Epoch 164/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0070 - d_loss: 0.5727\n",
      "Epoch 165/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0328 - d_loss: 0.5796\n",
      "Epoch 166/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0113 - d_loss: 0.5737\n",
      "Epoch 167/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0275 - d_loss: 0.5758\n",
      "Epoch 168/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0216 - d_loss: 0.5782\n",
      "Epoch 169/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0302 - d_loss: 0.5738\n",
      "Epoch 170/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0190 - d_loss: 0.5744\n",
      "Epoch 171/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0423 - d_loss: 0.5769\n",
      "Epoch 172/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0217 - d_loss: 0.5709\n",
      "Epoch 173/200\n",
      "71/71 [==============================] - 3s 49ms/step - g_loss: 1.0386 - d_loss: 0.5765\n",
      "Epoch 174/200\n",
      "71/71 [==============================] - 4s 49ms/step - g_loss: 1.0155 - d_loss: 0.5711\n",
      "Epoch 175/200\n",
      "71/71 [==============================] - 3s 49ms/step - g_loss: 1.0359 - d_loss: 0.5697\n",
      "Epoch 176/200\n",
      "71/71 [==============================] - 3s 49ms/step - g_loss: 1.0299 - d_loss: 0.5721\n",
      "Epoch 177/200\n",
      "71/71 [==============================] - 3s 49ms/step - g_loss: 1.0450 - d_loss: 0.5712\n",
      "Epoch 178/200\n",
      "71/71 [==============================] - 3s 49ms/step - g_loss: 1.0193 - d_loss: 0.5694\n",
      "Epoch 179/200\n",
      "71/71 [==============================] - 3s 49ms/step - g_loss: 1.0569 - d_loss: 0.5666\n",
      "Epoch 180/200\n",
      "71/71 [==============================] - 3s 49ms/step - g_loss: 1.0321 - d_loss: 0.5672\n",
      "Epoch 181/200\n",
      "71/71 [==============================] - 3s 49ms/step - g_loss: 1.0424 - d_loss: 0.5714\n",
      "Epoch 182/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0279 - d_loss: 0.5712\n",
      "Epoch 183/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0426 - d_loss: 0.5651\n",
      "Epoch 184/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0658 - d_loss: 0.5646\n",
      "Epoch 185/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0355 - d_loss: 0.5665\n",
      "Epoch 186/200\n",
      "71/71 [==============================] - 3s 48ms/step - g_loss: 1.0694 - d_loss: 0.5758\n",
      "Epoch 187/200\n",
      "71/71 [==============================] - 3s 47ms/step - g_loss: 1.0264 - d_loss: 0.5733\n",
      "Epoch 188/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 1.0687 - d_loss: 0.5712\n",
      "Epoch 189/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 1.0386 - d_loss: 0.5668\n",
      "Epoch 190/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 1.0531 - d_loss: 0.5613\n",
      "Epoch 191/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 1.0471 - d_loss: 0.5696\n",
      "Epoch 192/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 1.0722 - d_loss: 0.5675\n",
      "Epoch 193/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 1.0414 - d_loss: 0.5637\n",
      "Epoch 194/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 1.0706 - d_loss: 0.5655\n",
      "Epoch 195/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 1.0426 - d_loss: 0.5651\n",
      "Epoch 196/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 1.0703 - d_loss: 0.5641\n",
      "Epoch 197/200\n",
      "71/71 [==============================] - 3s 46ms/step - g_loss: 1.0492 - d_loss: 0.5628\n",
      "Epoch 198/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 1.0721 - d_loss: 0.5663\n",
      "Epoch 199/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 1.0423 - d_loss: 0.5628\n",
      "Epoch 200/200\n",
      "71/71 [==============================] - 3s 45ms/step - g_loss: 1.0651 - d_loss: 0.5649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f26a6499100>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_gan.fit(dataset, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAJOCAYAAACncEOxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABNIklEQVR4nO3deZRU9Z3//9ebTVlEwAURibhg3EVFNFGjxmiIxxmXRI27oxFnovlpxGQcsqjjJDGaGD2J0WkjA8kYkYkajYm7MZpI+ArENWDcQFEEEZFFZX3//ujKSRf3fS/V1bXeej7OqdPdr/5Q9amm3vSbW/dzP+buAgAAQKxbvScAAADQyGiWAAAAMtAsAQAAZKBZAgAAyECzBAAAkIFmCQAAIAPNUpWY2Rwz+0yJY93Mdizzccr+s0CtUA9AMWqiudAstRAz28jMJpjZUjN728wurvecgHoxsxPN7Ekz+8DMHqv3fIB6M7MfmNlLZrbMzGab2Rn1nlOj6FHvCaCmLpc0QtK2kraS9Hsz+6u731/XWQH1sVjSdZJ2lvTp+k4FaAgrJP2TpL9J2k/S/Wb2srs/Wd9p1R9HlmrAzEab2VQzW2Jm883sJ2bWa71hR5nZq2a2yMyuMbNuHf782WY2y8zeM7MHzGzbMqdyhqQr3f09d58l6WZJZ5V5X0BZGqUe3P1hd58i6a2uPB+gqxqoJi5z99nuvs7dp0l6QtInuvDUcoNmqTbWSvqqpM3V/sI7XNKX1xtznKRRkvaRdIyksyXJzI6VNF7S8ZK2UPuL97boQczsFDN7NuV7AyVtLemZDvEzknYr5wkBXVD3egAaTMPVhJn1VvvRpRc691TyiWapBtx9hrv/2d3XuPscSf8t6ZD1hn3f3Re7++tqf2vg5EJ+nqTvufssd18j6buSRkb/c3D3X7r7ninT6Ff4+H6H7H1Jm5T1pIAyNUg9AA2jQWviJrX/h/qBzj+j/KFZqgEz28nM7i2cVL1U7S/mzdcb9kaHz+eq/SiQ1H5+0fWFw7NL1H6ehUka2slpLC987N8h6y9pWSfvB+iSBqkHoGE0Wk2Y2TWSdpd0ort7ufeTJzRLtXGjpNmSRrh7f7UfMrX1xgzr8PnH9I/zKN6QdJ67D+hw693ZE+7c/T1J8yXt1SHeSxxiRe3VvR6ABtMwNWFmV0j6nKQj3X1pOfeRRzRLtbGJpKWSlpvZzpL+LRjzNTMbaGbDJF0o6fZCfpOk/zCz3STJzDY1sxPKnMfPJX2z8Dg7SzpX0sQy7wsoV0PUg5l1N7ON1b4quJuZbWxmPcu5L6CLGqUm/kPSKZKOcPd3y7mPvKJZqo1L1P4CXKb2FWi3B2PuljRD0tOSfivpFkly97skfV/S5MLh2efV3vUnmNmpZpZ1pOgySa+o/RDuHyRdw2UDUAeNUg+nS/pQ7f+rP7jw+c2dfzpAlzVKTXxX7UetXjKz5YXb+LKeUc4Yb0cCAACk48gSAABABpolAACADDRLAAAAGWiWAAAAMnRpI10zGyPpekndJf3M3a/awHjOJkc9LXL3Lar5ANQEmgw1ARQLa6LsI0tm1l3SDWpforirpJPNbNfy5wdU3dxq3jk1gSZETQDFwproyttwoyW97O6vuvsqSZPVvrkf0KqoCaAYNYFc6EqzNFTFe9XMU7AXjZmNNbPpZja9C48FNANqAihGTSAXunLO0vr71khS4r1md2+T1CbxXjRyj5oAilETyIWuHFmap+KN/bbRPzb2A1oRNQEUoyaQC11plp6SNMLMtjOzXpK+KOmeykwLaErUBFCMmkAulP02nLuvMbMLJD2g9iWhE9w9a4M+INeoCaAYNYG8qOlGurwXjTqb4e6j6j2JjqgJ1Bk1ARQLa4IreAMAAGSgWQIAAMhAswQAAJCBZgkAACADzRIAAEAGmiUAAIAMNEsAAAAZaJYAAAAydGUjXQAAUCG9evUK8379+iWyG264oeSxkjR79uxENm3atHDsY489Fubvv/9+mK9evTrM84QjSwAAABlolgAAADLQLAEAAGSgWQIAAMhAswQAAJCB1XB1ZmaJ7OMf/3g49qWXXgrztWvXVnROQLP7v//7v0R21FFHhWOHDh0a5kuWLKnklNCCon/fJenb3/52mJ999tlhHr1Gu3WLj3WkrUyLXv9pvztWrlwZ5jfffHOYf+1rXyv5vpsVR5YAAAAy0CwBAABkoFkCAADIQLMEAACQgWYJAAAgQ5dWw5nZHEnLJK2VtMbdR1ViUs0gbZXDoYceGubf+973wnzgwIGJbN26deHYhx56KMz/+te/JrKf/exn4dg1a9aEOSqjlWuiHnr27BnmO++8cyJL23cr7T5QGa1cE3vttVeYX3LJJWHep0+fME9b+RZJez1H//an/a7p27dvmH/pS18K86eeeiqRTZ48ORzr7mHe6Cpx6YDD3H1RBe4HyAtqAihGTaCp8TYcAABAhq42Sy7pQTObYWZjowFmNtbMppvZ9C4+FtAMqAmgGDWBptfVt+EOdPe3zGxLSQ+Z2Wx3f7zjAHdvk9QmSWbWnG9WAqWjJoBi1ASanlXqZCszu1zScnf/QcaY3BRBdAKpFJ/oJklvv/12mH/qU59KZAcccEA49vrrrw/z6FL4S5cuDceecsopYf7www+Hedql85vUjFqeXNpqNVEPw4cPD/MnnngikaUtbthll13C/KOPPip7Xk2EmqiiU089Ncx/8YtfhHnawqHo93Ta6/PPf/5zmM+bNy+RfexjHwvH7rvvvmHeu3fvMF+xYkUi22677cKxixcvDvMGEtZE2W/DmVlfM9vk759LOlLS8+XPD2hu1ARQjJpAXnTlbbjBku4qdMI9JP3S3e+vyKyA5kRNAMWoCeRC2c2Su78qKb6IBNCCqAmgGDWBvODSAQAAABlolgAAADJU4greuRetALjsssvCsRtvvHGYT5gwIczvu+++RNbZLUmWLVuWyAYMGBCOveeee8I8bSuVk046qaTHAxrJ4MGDE9mNN94Yjm2RVW+ogzfffDPM01a9pW0/8uyzzyayyy+/PBz74IMPhnm0oi5t1dt3v/vdMB85cmSYb7LJJons+9//fjj23HPPDfNGx5ElAACADDRLAAAAGWiWAAAAMtAsAQAAZKBZAgAAyFCxveFKerAm3fMn2r/t3nvvDcfOnj07zP/5n/85zKOVZStXrgzHpq2U6NEjuajx3//938OxF1xwQZhvvvnmYf7b3/42kZ111lnh2CVLloR52rzroKb7YJWiWWuiUfTt2zfMo9fiNddcE44dP358JafUbKiJOvjVr34V5tEea5J04YUXJrK0f28rIVrdJsWrTCXpmWeeSWRz5swJx6atqGugfUgruzccAABAK6BZAgAAyECzBAAAkIFmCQAAIAPbnXTQs2fPMI9OSItOqpbSL+W+cOHCMK/Eyc+rVq1KZN/5znfCsXfddVeYz5w5M8yjk9uPOeaYcOytt94a5p05ca+WCw7Q/NJeW9F2EmknzwK1Fm0jJUlr166t8UxiaVtapeXXX399IjvxxBPDsdtvv32Yv/jiiyXOrj44sgQAAJCBZgkAACADzRIAAEAGmiUAAIAMNEsAAAAZNrgazswmSDpa0kJ3372QDZJ0u6ThkuZIOtHd36veNGsjbcuPE044IZG99dZb4dhqrnrrjLTHe+2118I8bfuWgw8+OJFdcskl4dj9998/zH/6058msr/97W/h2I8++ijMG0kr1USjS1uV2q1b8v+Bn/zkJ6s9nZZFTXROo6x6q5To98fpp58ejr344ovD/LzzzqvonCqtlCNLEyWNWS+7VNIj7j5C0iOFr4FWMVHUBNDRRFETyLENNkvu/rikxevFx0iaVPh8kqRjKzstoHFRE0AxagJ5V+5FKQe7+3xJcvf5ZrZl2kAzGytpbJmPAzQLagIoRk0gN6p+BW93b5PUJklmxuWZ0fKoCaAYNYFGV+5quAVmNkSSCh/js5qB1kFNAMWoCeRGuUeW7pF0pqSrCh/vrtiM6mjPPfcM87322iuRPfTQQ+HYtNU5jSJtf6wzzjgjzHfeeedEdscdd4Rjzz777DCPVhmeddZZKTNsWrmsiUY3atSoMI/2hps9e3a1p4Ni1ESL2HrrrRPZNttsE44dM2b9dQDthg8fnsjmzJnTlWlV1AaPLJnZbZKmSvq4mc0zs3PU/uI/wsxeknRE4WugJVATQDFqAnm3wcMg7n5yyrcOr/BcgKZATQDFqAnkHVfwBgAAyECzBAAAkIFmCQAAIENjL92qkmiljCStWrUqzHv16pXIpk+fHo6dP39++ROro+XLl4d59Dx/9KMfhWN/+MMfhvlnP/vZRNa7d+9OzQOtLdrrTZI+//nPh/kHH3yQyB544IGKzglAu4MOOqjksWmr5EaMGJHImmo1HAAAQCujWQIAAMhAswQAAJCBZgkAACBDS57gPWjQoDCPLtkuxSeE/+IXvwjHrlmzpvyJNYkpU6aE+dVXXx3mPXv2TGSrV6+u6JyQb1tssUWYn3baaWF+//33J7KpU6dWdE5AR9EihO7du4djN9100zBftGhRRedUaWlblZx33nkl30fa78gZM2aUNada4cgSAABABpolAACADDRLAAAAGWiWAAAAMtAsAQAAZGjJ1XAbbbRRmO+3335h/v777yeyd955p6JzaibvvfdemPfoEb+cXnrppUQW/UyBNMOGDQvztJWtM2fOTGTLli2r6JzQmtJ+f/z2t79NZGmrOHfccccwv/POO8N8/PjxiSxt5dzatWvDPFqt17dv33Dst771rTD/yle+UvJ9p83jyiuvDPNG/53AkSUAAIAMNEsAAAAZaJYAAAAy0CwBAABkoFkCAADIsMHVcGY2QdLRkha6++6F7HJJ50r6+5Kw8e7+u2pNstLSVm3tsMMOYf7WW28lsmi/uFaRtt9Rmra2tkTm7pWaTs3lsSYa3Re+8IVOjR84cGCVZoJIHmsi7d+5a665JswPP/zwLj/mwQcfHOZPPvlkIjvnnHPCsXPmzAnzaOVo2irTzqx6SxP93pTS9xBNWz3XKEp55hMlRbvn/cjdRxZuTVMAQAVMFDUBdDRR1ARybIPNkrs/LmlxDeYCNAVqAihGTSDvunLO0gVm9qyZTTCz1GPeZjbWzKab2fQuPBbQDKgJoBg1gVwot1m6UdIOkkZKmi/ph2kD3b3N3Ue5+6gyHwtoBtQEUIyaQG6Utd2Juy/4++dmdrOkeys2oxoYMmRImI8cOTLMo+091q1bV8kpNZV99903zFesWBHm8+bNS2RpJwo268+12Wui0XV2e6Htt9++SjNBqZqpJqItTI477rhw7Lnnntvlx0v7d65///5h/uabbyayL33pS+HYtFqJHnP48OHh2M6cyC3FC3bS5rdq1apO3XejKOvIkpl17DaOk/R8ZaYDNCdqAihGTSBPSrl0wG2SDpW0uZnNk3SZpEPNbKQklzRH0nnVmyLQWKgJoBg1gbzbYLPk7icH8S1VmAvQFKgJoBg1gbzjCt4AAAAZaJYAAAAylLUartl99rOfDfMBAwaEed++fRNZs67a6qxoVcRRRx0Vjl28OL4mXXSZ/Vb5+aEy+vTpE+Zpr6P//u//ruZ0kDP7779/IrvpppvCsb169ery46Vtl5X2Oyjavme33Xbr1H1HK9Yq9e/wSy+9lMgefvjhitx3o+DIEgAAQAaaJQAAgAw0SwAAABlolgAAADLQLAEAAGRoydVwq1evDvONN9645PtoldVcm222WSLbZZddwrG33357mE+ZMqWic0K+Rat59ttvv3Bs2j5T06ZNq+ickG/RiueePXuGY6NVZWnSxqatWOuMStxH2u/CtL3h0h5zu+22S2Tjxo0Lx15zzTUlzq6xcGQJAAAgA80SAABABpolAACADDRLAAAAGWiWAAAAMlhnzuzv8oOZ1e7BMvTr1y/M33jjjZLHb7rppuHYDz74oPyJ1VHaSsA77rgjkaWtEvnTn/4U5ldccUX5E6usGe4+qt6T6KhRaqKRRCtx0mrzlVdeCfNDDz00kbXKCtZOoiYkjR49OpHde++94dj+/fuHebRnXNprrnv37mG+bNmyMJ8xY0Yi23vvvcOxaSvW3nvvvUT26KOPhmM//elPh/mwYcPCPKrZNWvWhGOb4HdnWBMcWQIAAMhAswQAAJCBZgkAACADzRIAAECGDW53YmbDJP1c0laS1klqc/frzWyQpNslDZc0R9KJ7p48g6wBLV++PMxnzpwZ5tHJbnfffXc49uyzzw7ztBNUay06CVGSTjjhhDDfYostEtkNN9wQjk07ITJv8lgTjaRHj+Q/SxtttFE49plnngnzWi5cQfPXxF//+tdEtueee4Zj99hjjzDfYYcdEtmiRYvCsStXrgzzZ599NswXLlyYyLbddttwbNp2VFOnTk1k77zzTjh24MCBYf7Tn/40zI8//vhEFtWxJF155ZVhnrY9SqMo5cjSGknj3H0XSQdIOt/MdpV0qaRH3H2EpEcKXwOtgJoAilETyLUNNkvuPt/dZxY+XyZplqShko6RNKkwbJKkY6s0R6ChUBNAMWoCebfBt+E6MrPhkvaWNE3SYHefL7UXipltmfJnxkoa28V5Ag2JmgCKURPIo5KbJTPrJ+kOSRe5+9K0C1+tz93bJLUV7oMTCZAb1ARQjJpAXpW0Gs7Meqq9AG519zsL8QIzG1L4/hBJyTPQgJyiJoBi1ATyrJTVcCbpFkmz3P3aDt+6R9KZkq4qfIyXhzWR8847L8wfeOCBRHb44YeHY3/wgx+E+YUXXhjm0SqHNGkrfHr37p3I0lZE3HzzzWG++eabh/mPf/zjRHb77beHYz/66KMwz5tWqol6iF6LAwYMCMcuWLAgzKPtF9auXduleSFds9dEtEI6bdX0kiVLwvz3v/99Ikvb8qMSZs+e3am8M9JW8Z1xxhlhvu+++yayLbcM33HV7rvvXv7E6qiUt+EOlHS6pOfM7OlCNl7tL/4pZnaOpNclxWvPgfyhJoBi1ARybYPNkrv/UVLaG8/x4RUgx6gJoBg1gbzjCt4AAAAZaJYAAAAy0CwBAABk6NRFKfPu5ZdfDvPzzz8/kd10003h2MMOOyzMf/KTn4T5//zP/ySyefPmhWO32WabMP/f//3fRJa2L8+HH34Y5hdffHGY33bbbYmMVUWoppNOOqnksSeeeGKYR/WZtsIH6IxWWfUbSXvuxxxzTCKbNm1aOHbKlCkVnVOtcGQJAAAgA80SAABABpolAACADDRLAAAAGTjBuwT3339/Ijv00EPDsdH2IJJ05JFHhvlnP/vZRJZ2Et3GG28c5m+88UYiSzuJ7tFHHw3zxx9/PMyBWou2Klm3bl04dsaMGWGetlUFmkO0AW/adk+ovxdeeCGR7bbbbuHYZcuWhXm0KKma28V0FkeWAAAAMtAsAQAAZKBZAgAAyECzBAAAkIFmCQAAIIPVcoWBmbXscobevXuH+aabbprI0rYkWbVqVZh37949kbEaKDTD3UfVexIdtXJNoCE0ZE10ZkUkUGFhTXBkCQAAIAPNEgAAQAaaJQAAgAw0SwAAABlolgAAADJscG84Mxsm6eeStpK0TlKbu19vZpdLOlfSO4Wh4939d9WaaLNLW+GWlqNxURNAsUrXBCvf0GhK2Uh3jaRx7j7TzDaRNMPMHip870fu/oPqTQ9oSNQEUIyaQK5tsFly9/mS5hc+X2ZmsyQNrfbEgEZFTQDFqAnkXafOWTKz4ZL2ljStEF1gZs+a2QQzG5jyZ8aa2XQzm961qQKNh5oAilETyCV3L+kmqZ+kGZKOL3w9WFJ3tTdc35E0oYT7cG7c6nibXurrnZrg1iI3aoIbt+JbWBMlHVkys56S7pB0q7vfKUnuvsDd17r7Okk3Sxpdyn0BeUBNAMWoCeTZBpslMzNJt0ia5e7XdsiHdBh2nKTnKz89oPFQE0AxagJ5V8pquAMlnS7pOTN7upCNl3SymY1U+2GrOZLOq8L8gEZETQDFqAnkmhXeI67Ng7HDOuqrIXdYr/cc0NKoCaBYWBNcwRsAACADzRIAAEAGmiUAAIAMNEsAAAAZaJYAAAAy0CwBAABkoFkCAADIQLMEAACQoZQreFfSIklzC59vXvg6z3iOjWXbek8gQE3kTzM9R2qi/niOjSWsiZpewbvogc2mN9qVYyuN54jOaIWfJc8RndEKP0ueY3PgbTgAAIAMNEsAAAAZ6tkstdXxsWuF54jOaIWfJc8RndEKP0ueYxOo2zlLAAAAzYC34QAAADLQLAEAAGSoebNkZmPM7EUze9nMLq3141eLmU0ws4Vm9nyHbJCZPWRmLxU+DqznHLvCzIaZ2e/NbJaZvWBmFxby3DzHeqEmmhM1UT3URHPKc03UtFkys+6SbpD0OUm7SjrZzHat5RyqaKKkMetll0p6xN1HSHqk8HWzWiNpnLvvIukASecX/u7y9Bxrjppo6tcLNVEF1ERTv15yWxO1PrI0WtLL7v6qu6+SNFnSMTWeQ1W4++OSFq8XHyNpUuHzSZKOreWcKsnd57v7zMLnyyTNkjRUOXqOdUJNNClqomqoiSaV55qodbM0VNIbHb6eV8jyarC7z5faX0SStqzzfCrCzIZL2lvSNOX0OdYQNZED1ERFURM5kLeaqHWzZEHGtQuaiJn1k3SHpIvcfWm955MD1ESToyYqjppocnmsiVo3S/MkDevw9TaS3qrxHGppgZkNkaTCx4V1nk+XmFlPtRfAre5+ZyHO1XOsA2qiiVETVUFNNLG81kStm6WnJI0ws+3MrJekL0q6p8ZzqKV7JJ1Z+PxMSXfXcS5dYmYm6RZJs9z92g7fys1zrBNqoklRE1VDTTSpPNdEza/gbWZHSbpOUndJE9z9OzWdQJWY2W2SDpW0uaQFki6T9GtJUyR9TNLrkk5w9/VP7msKZnaQpCckPSdpXSEer/b3o3PxHOuFmmjO1ws1UT3URHO+XvJcE2x3AgAAkIEreFeJmc0xs8+UONbNbMcyH6fsPwvUCvUAFKMmmgvNUgsxs6vN7A0zW2pmc83sG/WeE1BvhasLv2Nmf6z3XIB6MrOJZrbKzJZ3uHWv97waAc1Sa7lF0s7u3l/SJyWdYmbH13lOQL19X+0XzwMgXe3u/Trc1tZ7Qo2AZqkGzGy0mU01syVmNt/MflJY5dHRUWb2qpktMrNrzKxbhz9/dmGvnffM7AEz27acebj7i+6+okO0ThKHZ1FTjVIPhfv6hKTdJf1PufcBdFUj1QRiNEu1sVbSV9W+AuITkg6X9OX1xhwnaZSkfdR+afizJcnMjlX7aoLjJW2h9pUGt0UPYmanmNmzWRMxs0vNbLnar2XSV9Ivy3pGQPkaoh7sH3uQXSAueoj6aoiaKPiymS02sxlm9vmynk0euTu3KtwkzZH0mZTvXSTprg5fu6QxHb7+sto3HZSk+ySd0+F73SR9IGnbDn92x07OzdR+GforJG1S758Vt/zfGrEe1P7L6cbC52dJ+mO9f07cWufWoDWxj6TNJPWQdJSkZZIOrPfPqhFuHFmqATPbyczuNbO3zWyppO+q/X8QHXXcC2mupK0Ln28r6frC4dklat+E0dSFvZK83V8kfaj2hgmomUaoBzPbWtL/J4lFDqi7RqgJSXL3me7+rruvcfffSbpV7UesWh7NUm3cKGm2pBHefnL1eCX3P+p4ef+P6R+X939D0nnuPqDDrbe7P1mBefWQtEMF7gfojEaoh9GShkj6q5m9Lel6SaMLv6xY/YNaa4SaiHgwj5ZEs1Qbm0haKmm5me0s6d+CMV8zs4FmNkzShZJuL+Q3SfoPM9tNksxsUzM7obMTMLNuZnZe4THMzEZLOl/SI+U8IaAL6l4Pan/rYrikkYXbtyX9RdJIZ/UPaq8RakJm9gUz61f4fXGkpNOU761mSkazVBuXSDpF7e//3qx/vMg7ulvSDElPS/qt2pf5y93vUvvS5smFw7PPS/pc9CBmdqqZvZAxj+MkvVKYx/9K+nHhBtRS3evB3Ve6+9t/v0l6X9LqwudArdW9JgoulPSmpCWSrpF0rrs/1ulnk0NsdwIAAJCBI0sAAAAZaJYAAAAy0CwBAABkoFkCAADI0KMrf9jMxqj9+iTdJf3M3a/awHjOJkc9LXL3Lar5ANQEmgw1ARQLa6LsI0sd9lX6nKRdJZ1sZruWPz+g6uZW886pCTQhagIoFtZEV96GGy3pZXd/1d1XSZqs9s39gFZFTQDFqAnkQleapaEq3qtmnoK9aMxsrJlNN7PpXXgsoBlQE0AxagK50JVzlqL9YhLvNbt7m6Q2ifeikXvUBFCMmkAudOXI0jwVb+y3jf6xsR/QiqgJoBg1gVzoSrP0lKQRZradmfWS9EWx4R5aGzUBFKMmkAtlvw3n7mvM7AJJD6h9SegEd8/aoA/INWoCKEZNIC9qupEu70Wjzma4+6h6T6IjagJ1Rk0AxcKa4AreAAAAGWiWAAAAMtAsAQAAZKBZAgAAyECzBAAAkIFmCQAAIAPNEgAAQAaaJQAAgAxd2UgXAABI6tYteezBLNpHWFq7dm21p4MK48gSAABABpolAACADDRLAAAAGWiWAAAAMtAsAQAAZGA1XIUNHTo0zL/whS+E+dFHH53I1qxZE4792te+FuYvvPBCInP3tCkCLWndunWdGh+tbgLSHHDAAYnsL3/5Szj2ww8/rPZ0UGH8awAAAJCBZgkAACADzRIAAEAGmiUAAIAMXTrB28zmSFomaa2kNe4+qhKTApoVNQEUoyaQB5VYDXeYuy+qwP00rFGjkrV92223hWO33377ME9b4dajR/KvIG0/oSOOOCLMp06dmsjOOuuscOwrr7wS5qio3NdEo+vXr18iW7JkSTg2Wk0qSd27dw9z9vUqS25qom/fvmE+efLkRLbzzjuHYwcMGNCp/FOf+lQiS/u3fOuttw7zAw88MJH90z/9Uzj2tddeC/NvfOMbYf7//t//S2R5W5HN23AAAAAZutosuaQHzWyGmY2NBpjZWDObbmbTu/hYQDOgJoBi1ASaXlffhjvQ3d8ysy0lPWRms9398Y4D3L1NUpskmVm+jssBSdQEUIyaQNPr0pEld3+r8HGhpLskja7EpIBmRU0AxagJ5EHZR5bMrK+kbu6+rPD5kZL+s2IzayDRidU77rhjODbtpLa0rRPefvvtRDZo0KBw7MYbbxzmn/zkJxPZE088EY4944wzwvyRRx4J87ydpFdNeayJtNdtZ7cOqbUPPvggkaXNOaofSbr66qvDfNy4ceVPrMXksSbSTtqO/n1OWwyQdqL0xRdfHObR/Xz00Ufh2F69eoX5RhttFOaRtIVKhx9+eJjPnj07ke25557h2NWrV5c8j0bSlbfhBku6q7Byq4ekX7r7/RWZFdCcqAmgGDWBXCi7WXL3VyXtVcG5AE2NmgCKURPICy4dAAAAkIFmCQAAIAPNEgAAQIZKbHeSe48++mgiW7ZsWTh27ty5YX7DDTeE+fTpyWuwffWrXw3HnnDCCWlTTNhyyy3D/Prrrw/zgw46KMzfe++9kh8T+ZO2HcIDDzyQyNJW59TDpptumsj69+8fjl28eHGYp62ei1YbrVq1qhOzQzPr3bt3mEcr1tK2LznvvPM69ZjPPPNMInv22WfDsWk1O3DgwESWtlov2oZLSt+Ka6uttkpkadsFNetqOI4sAQAAZKBZAgAAyECzBAAAkIFmCQAAIAPNEgAAQAZWw5Vg2rRpiWyPPfYIx26xxRZhPnPmzDCPVtyceuqp4di01Q9nn312Ikvb2ydtRdBmm20W5qyGa21pK2uifZ/+67/+Kxxbj/0FoxVrafOYP39+mF933XVhzsq31jZixIgw79OnTyJ7/fXXw7Fpq8ouuOCCML/pppsSWdrrOW0ldLR33aJFizp1H/vtt1+Y33fffYmskVbHVgJHlgAAADLQLAEAAGSgWQIAAMhAswQAAJCBE7zL9NZbb4V52mXiO3OSa8+ePcP8iCOOCPOtt946kaVt1fDqq6+G+ZIlS0qbHFpK2snP48aNS2QTJ04Mx77xxhuVnFJJopNZ0+rqnXfeCfMPP/ywonNCPpx77rlhHi2eSft3//777w/ztra2MO/M74+FCxeWPDbNnDlzOpW3Ao4sAQAAZKBZAgAAyECzBAAAkIFmCQAAIAPNEgAAQIYNroYzswmSjpa00N13L2SDJN0uabikOZJOdPeW2hdjr732CvM//vGPYZ62Ou1HP/pRIjv66KPDsTvuuGOYR6t8VqxYEY597LHHwpzVcKVrpZp48sknw/zLX/5yIjvttNPCsd/73vcqOqdypW0xse+++4b5qFGjwvzBBx+s2JzyopVqIlp9LMX/xr/99tvh2JdeeinMhwwZEuYHHHBAIktbmZZ239H2IytXrgzHIqmUI0sTJY1ZL7tU0iPuPkLSI4WvgVYxUdQE0NFEURPIsQ02S+7+uKTF68XHSJpU+HySpGMrOy2gcVETQDFqAnlX7kUpB7v7fEly9/lmFm9RLMnMxkoaW+bjAM2CmgCKURPIjapfwdvd2yS1SZKZlX4ZUiCnqAmgGDWBRlfuargFZjZEkgofu359daC5URNAMWoCuVHukaV7JJ0p6arCx7srNqMmcfDBB4d5r169OnU/0T5DvXv3DseuWrUqzF9++eVElrb30LHHHhvmaSt8otVQndmnqIXksiaiPdak9D0QI926xf8nS1shWgn77LNPIkt73abtGTdjxoyKzqkFNXVNRHu9SVLfvn3DPHqdp9XJmWeeGeZf+cpXwjxtJWe1pNXKVVddFea33HJLInvllVcqOqd62+CRJTO7TdJUSR83s3lmdo7aX/xHmNlLko4ofA20BGoCKEZNIO82+N9Ddz855VuHV3guQFOgJoBi1ATyjit4AwAAZKBZAgAAyECzBAAAkMFqubIpT9fPSFvhE+3hI0l77rlnmP/+979PZM8880w4Nm1lxfLlyxNZ2qq8tJU/aSuT/vVf/zWRTZ48ORz74YcfhnkDmeHu8YZfddLoNTF2bHydwB//+MeJLG31WNrK0bVr15Y/sQ1YtGhRIhs0aFA4Nm0fxWilqiRNmTIlkVVzZV+VURMpunfvHuavvfZamA8bNqya02kIaa/zDz74IJGl7WW6YMGCis6pCsKa4MgSAABABpolAACADDRLAAAAGWiWAAAAMlR9I928SjvRLdoeJCuPbLllvDn3vvvuG+ZbbbVVIotOuJOkH/zgB2E+ePDgMD/77LMT2dSpU8Oxs2fPDnM0r2XLloV5tMBhjz32CMemvW6nT58e5lFtpS1uuOCCC8I8Opk7rWajBRKS9JnPfCbM77rrrkS2cuXKcCyaV9oChKuvvjrMv/WtbyWyAQMGhGPTFghNmjQpzMeNG5fItt1223Ds9ttvH+a77bZbInvrrbfCsQsXxtv4pZ2c/cQTTySyb3/72+HY888/P8wbHUeWAAAAMtAsAQAAZKBZAgAAyECzBAAAkIFmCQAAIEPNtzuJVgE08VYBTSdtpUTaCrc+ffoksrRVTIcffniYN9DfL1s7dNL+++8f5jfccEMi22uvvcKxaf/GvP/++2EerRxN26bnyCOPDPNoq4q07XhWrVoV5vfff3+YR9ugpK0abALURCelrWTr379/Ikvbdmrx4sVhnrYCrzO/p9PmF/07nLalS9rjbbbZZmEerdZLW/U2cODAMF+zZk2Y1wHbnQAAAHQWzRIAAEAGmiUAAIAMNEsAAAAZaJYAAAAybHBvODObIOloSQvdffdCdrmkcyW9Uxg23t1/V8oDNtDKqJaUtgIpbQVF7969E1kDrVqoi0rXRCObNm1amB922GGJ7He/i5/uNttsE+Zpe1v98z//c4mzS1+1E+331rdv33Bs2kq7vffeO8yjFYIPP/xw2hRbQivVRNrvsNWrVyeytFWSafdRidXpnfkdmzY27fdBWn7mmWeW/JhpdZj2u6lRlHJkaaKkMUH+I3cfWbg1fQEAnTBR1ATQ0URRE8ixDTZL7v64pPiiEEALoiaAYtQE8q4r5yxdYGbPmtkEM4uvMiXJzMaa2XQzi69kCOQHNQEUoyaQC+U2SzdK2kHSSEnzJf0wbaC7t7n7qEa7SixQYdQEUIyaQG5s8ATviLsv+PvnZnazpHsrNiNUVXTiqyTNnj07zPfZZ59E9s477wQjJTMrf2JNrtVqIjpx9eCDDw7HbrLJJmF+0EEHhfmOO+6YyPbYY49wbLTFhCQNGzYskaVt3ZK2xcS1114b5n/4wx/CHMXyWhNpJzmfeuqpiWzKlCnh2CVLllRySmVLO6E8rSbSnvumm25a8tiVK1eWOLvGUtaRJTMb0uHL4yQ9X5npAM2JmgCKURPIk1IuHXCbpEMlbW5m8yRdJulQMxspySXNkXRe9aYINBZqAihGTSDvNtgsufvJQXxLFeYCNAVqAihGTSDvuII3AABABpolAACADGWthkPz6tEj/it/+umnw3zkyJGJ7KmnngrHspUNImlbPtx3330l30faSsu0PFqJM3fu3HDs4MGDwzxa3SRJ99xzTyKbP39+OBbNK20118KFC8N8s802S2Q33XRTOHb06NFhPn16Y1xmKu25T548OcyjLYP+9Kc/hWM/+uij8idWRxxZAgAAyECzBAAAkIFmCQAAIAPNEgAAQAaaJQAAgAyshmsxhx9+eJgfddRRYf7BBx8ksrS9sdL2GQK6Ku21lZZHKzOvu+66cOz48ePDPG0/urSVQsiXK6+8MswHDRpU8n2krdY86aSTwrzWq+HS5veJT3wizKPV0ZK0Zs2aRHbaaaeVPa9GRNUDAABkoFkCAADIQLMEAACQgWYJAAAgA80SAABABlbD5UC0oqFPnz7h2LS9ioYMGRLmDzzwQCKbNWtWJ2YHNIa01XCnnHJKmG+33XZh/q//+q+J7Nvf/nY4lhWizSFa4XjkkUeGY9NWkEV/12vXrg3H7rzzzmEe7bEmxavNOvvain4n7LrrruHYRx99NMx79eoV5r/85S8T2ZtvvtmJ2TU+jiwBAABkoFkCAADIQLMEAACQgWYJAAAgwwZP8DazYZJ+LmkrSesktbn79WY2SNLtkoZLmiPpRHd/r3pTrZ8dd9wxkb33XvxUFy9eHOaVONGzd+/eYf6FL3whkX3zm98Mx2611VZh/txzz4X55Zdfnsg+/PDDlBm2BmqiOa1evTrML7nkkjC/+uqrw3zbbbdNZP379w/Hvv/++2Heo0fyn97oJN5m0ew1EW2Pc+yxx4Zj77vvvjDfeuutE9m7774bjk37u/7iF78Y5tG/zyNGjAjH7rfffmE+ZsyYku+je/fuYT5//vwwv/jiixNZ3hY3lHJkaY2kce6+i6QDJJ1vZrtKulTSI+4+QtIjha+BVkBNAMWoCeTaBpsld5/v7jMLny+TNEvSUEnHSJpUGDZJ0rFVmiPQUKgJoBg1gbzr1HWWzGy4pL0lTZM02N3nS+2FYmZbpvyZsZLGdnGeQEOiJoBi1ATyqORmycz6SbpD0kXuvjTtwlzrc/c2SW2F+8jXm5hoadQEUIyaQF6VtBrOzHqqvQBudfc7C/ECMxtS+P4QSQurM0Wg8VATQDFqAnlmGzpj3dr/azBJ0mJ3v6hDfo2kd939KjO7VNIgd//6Bu6rKf/HEG1lcOihh4Zj01bcTJ48Ocyjn/+WW4ZHqnX66aeH+U477ZTIli1bFo59/vnnwzzawkGS/va3vyWyaOVIk5jh7qO6eifURL6kbTHx4osvhvk+++yTyH7xi1+EY88444wwj1bJ1amuqIlO2muvvcL8G9/4RiJLW8Gc9ntil112CfPod0La63ajjTYK81WrViWy73znO+HY/fffP8y/8pWvhPm8efPCvEmFNVHK23AHSjpd0nNm9nQhGy/pKklTzOwcSa9LOqFCEwUaHTUBFKMmkGsbbJbc/Y+S0t54Pryy0wEaHzUBFKMmkHdcwRsAACADzRIAAEAGmiUAAIAMG1wNV9EHa/BVDmkGDBiQyMaPHx+OvfDCC8M8beXCokWLEtnKlSvDsf369QvzqVOnJrJbb701HPvggw+G+TvvvBPmOVORlT+V1Kw10QouuuiiMG9ra0tkvXr1Csem7Q3XQPtmURMV0q1b8thD2nWmorFSvO+gFO8lt91224Vjoz3qJGnzzTdPZFOmTAnHLlwYX+Fh7dq1YZ4zYU1wZAkAACADzRIAAEAGmiUAAIAMNEsAAAAZSt5It5UtWbIkkT366KPh2M9+9rNhHm1JIkmbbrppInv11VfDsVdffXWY//rXv05kb7/9djg27TL7AIo9/PDDYb777rsnsueee67a00GD68x2NWknSr/88ssl38fcuXPDPG3xQHSyeQMtNGh4HFkCAADIQLMEAACQgWYJAAAgA80SAABABpolAACADGx3UmFpl7fv27dvmK9atSqRRZe2l9JXLrCioWRs7YCqSNu+Ii1Pq/E6oCaAYmx3AgAA0Fk0SwAAABlolgAAADLQLAEAAGSgWQIAAMiwwWbJzIaZ2e/NbJaZvWBmFxbyy83sTTN7unA7qvrTbXzuHt6WL18e3latWpW4rVu3Lryl3Tdqi5rA+tJqNu2WN9QE8q6UjXTXSBrn7jPNbBNJM8zsocL3fuTuP6je9ICGRE0AxagJ5NoGmyV3ny9pfuHzZWY2S9LQak8MaFTUBFCMmkDedeqcJTMbLmlvSdMK0QVm9qyZTTCzgSl/ZqyZTTez6V2bKtB4qAmgGDWBXEo7DyY4L6afpBmSji98PVhSd7U3XN+RNKGE+3Bu3Op4m17q652a4FaJW7du3cJbvefV4UZNcONWfAtroqQjS2bWU9Idkm519zslyd0XuPtad18n6WZJo0u5LyAPqAmgGDWBPCtlNZxJukXSLHe/tkM+pMOw4yQ9X/npAY2HmkCpWmg1HDWBXCtlNdyBkk6X9JyZPV3Ixks62cxGqv2w1RxJ51VhfkAjoiaAYtQEcs1qeZ0edpNGnbHDOlCMmgCKhTXBFbwBAAAy0CwBAABkoFkCAADIQLMEAACQgWYJAAAgA80SAABABpolAACADDRLAAAAGUq5gnclLZI0t/D55oWv84zn2Fi2rfcEAtRE/jTTc6Qm6o/n2FjCmqjpFbyLHthseqNdObbSeI7ojFb4WfIc0Rmt8LPkOTYH3oYDAADIQLMEAACQoZ7NUlsdH7tWeI7ojFb4WfIc0Rmt8LPkOTaBup2zBAAA0Ax4Gw4AACADzRIAAECGmjdLZjbGzF40s5fN7NJaP361mNkEM1toZs93yAaZ2UNm9lLh48B6zrErzGyYmf3ezGaZ2QtmdmEhz81zrBdqojlRE9VDTTSnPNdETZslM+su6QZJn5O0q6STzWzXWs6hiiZKGrNedqmkR9x9hKRHCl83qzWSxrn7LpIOkHR+4e8uT8+x5qiJpn69UBNVQE009esltzVR6yNLoyW97O6vuvsqSZMlHVPjOVSFuz8uafF68TGSJhU+nyTp2FrOqZLcfb67zyx8vkzSLElDlaPnWCfURJOiJqqGmmhSea6JWjdLQyW90eHreYUsrwa7+3yp/UUkacs6z6cizGy4pL0lTVNOn2MNURM5QE1UFDWRA3mriVo3SxZkXLugiZhZP0l3SLrI3ZfWez45QE00OWqi4qiJJpfHmqh1szRP0rAOX28j6a0az6GWFpjZEEkqfFxY5/l0iZn1VHsB3OrudxbiXD3HOqAmmhg1URXURBPLa03Uull6StIIM9vOzHpJ+qKke2o8h1q6R9KZhc/PlHR3HefSJWZmkm6RNMvdr+3wrdw8xzqhJpoUNVE11ESTynNN1PwK3mZ2lKTrJHWXNMHdv1PTCVSJmd0m6VBJm0taIOkySb+WNEXSxyS9LukEd1//5L6mYGYHSXpC0nOS1hXi8Wp/PzoXz7FeqInmfL1QE9VDTTTn6yXPNcF2JwAAABm4gneVmNkcM/tMiWPdzHYs83HK/rNArVAPQDFqornQLLUYM/uMmc00sxVm9oaZnVjvOQH1ULjC8PIOtzVm9pt6zwuol8KVtm83s0WF261m1r/e82oENEstpHAl1V9K+oakTSWNlDSjnnMC6sXdd3P3fu7eT9Imaj+X4v/qPC2gnv5L0kBJ20vaQdJgSZfXc0KNgmapBsxstJlNNbMlZjbfzH5SWOXR0VFm9mqhm7/GzLp1+PNnF/baec/MHjCzbcucyjcl/be73+fua9z9XXd/pewnBpShgeqho0+p/UJ5d1TgvoBOaaCa2E7Sr919qbu/L+kuSbuVeV+5QrNUG2slfVXtKyA+IelwSV9eb8xxkkZJ2kftl4Y/W5LM7Fi1ryY4XtIWal9pcFv0IGZ2ipk9mzGPAwrjnisU5P+a2aAynxNQrkaph47OlPQrd1/RmScCVEij1MQNko42s4HWvtnt5yXdV95Tyhl351aFm6Q5kj6T8r2LJN3V4WuXNKbD119W+6aDUvsL9ZwO3+sm6QNJ23b4szuWOKdVhXntJOnvV1i9td4/K275vzViPXS4jz6Slko6tN4/J26tc2vEmpC0taSH1b7sf52khyT1qvfPqhFuHFmqATPbyczuNbO3zWyppO+q/X8QHXXcC2mu2l+0krStpOsLh2eXqH0TRlN5eyV9KOl/3P1v7r68MI+jyrgfoGwNVA9/d3zhfv7QhfsAytZANfF/kv6m9nP4+kt6RdL/lnE/uUOzVBs3SpotaYS791f7IdP19z/qeHn/j+kfl/d/Q9J57j6gw623uz9ZxjyeFXssof4apR7+7kxJP/fCf62BOmiUmthL7ee1rij8h/om8R9qSTRLtbKJ2g/zLzeznSX9WzDma4X3iYdJulDS7YX8Jkn/YWa7SZKZbWpmJ5Q5j/+R9C9mtr2Z9ZH075LuLfO+gHI1Sj3IzLaRdJikSeXeB1ABjVITT0n6kpn1NrPeksZKeqbM+8oVmqXauETSKZKWSbpZ/3iRd3S32pfxPy3pt2rfX0fufpek70uaXDg8+7ykz0UPYmanmtkLaZNw9wmSfq72S8/PlbRS0v9X1jMCytcQ9VBwuqSpzqpQ1Fej1MTZkoarfTPjN9V+CYGzOvtk8ojtTgAAADJwZAkAACADzRIAAEAGmiUAAIAMNEsAAAAZenTlD5vZGEnXS+ou6WfuftUGxnM2OeppkbtvUc0HoCbQZKgJoFhYE2UfWTKz7mrfR+ZzknaVdHJhV3ugUc2t5p1TE2hC1ARQLKyJrrwNN1rSy+7+qruvkjRZ7Zv7Aa2KmgCKURPIha40S0NVvFfNPAV70ZjZWDObbmbTu/BYQDOgJoBi1ARyoSvnLK2/b40U7Dvm7m2S2iTei0buURNAMWoCudCVI0vzVLyx3zb6x8Z+QCuiJoBi1ARyoSvN0lOSRpjZdmbWS9IXJd1TmWkBTYmaAIpRE8iFst+Gc/c1ZnaBpAfUviR0grtvaNNKILeoCaAYNYG8qOlGurwXjTqb4e6j6j2JjqgJ1Bk1ARQLa4IreAMAAGSgWQIAAMjQpe1OkH89eiRfIqtWrQrHfuUrXwnzG264oaJzAgCgljiyBAAAkIFmCQAAIAPNEgAAQAaaJQAAgAw0SwAAABlYDYdMV1xxRSIzi/bGlH7yk5+EOavhAADNjCNLAAAAGWiWAAAAMtAsAQAAZKBZAgAAyECzBAAAkIHVcC2me/fuYb7llluG+cUXX1zyfa9cubKsOQEA0Mg4sgQAAJCBZgkAACADzRIAAEAGmiUAAIAMXTrB28zmSFomaa2kNe4+qhKTApoVNQEUoyaQB5VYDXeYuy+qwP2gBgYNGhTmM2bMCPONN9645Pt+5513yppTDlETQDFqIsd69Ei2EmvXru3Ufbh7paZTFbwNBwAAkKGrzZJLetDMZpjZ2GiAmY01s+lmNr2LjwU0A2oCKEZNoOl19W24A939LTPbUtJDZjbb3R/vOMDd2yS1SZKZNfZxNqDrqAmgGDWBptelI0vu/lbh40JJd0kaXYlJAc2KmgCKURPIg7KPLJlZX0nd3H1Z4fMjJf1nxWaGqjjssMPCfPDgwWEenaS3bNmycOxZZ51V9rzygJqI7b777mGetnjgww8/TGQrVqwIxx544IFhPnLkyES2aFF8fvH3v//9MEfXURONrVevXmG+/fbbh/n5558f5ieddFIie/fdd8OxkydPDvNf/epXieyvf/1rOLYeJ4N35W24wZLuMrO/388v3f3+iswKaE7UBFCMmkAulN0sufurkvaq4FyApkZNAMWoCeQFlw4AAADIQLMEAACQgWYJAAAgg9XyrHKun1E7aauEHnrooTBfs2ZNmM+bNy+R7b///uHY1atXh/lHH30U5nUwo9H2pcpTTXTrFv/fq62tLcxPPfXUMI9ei3379u3UXAonFBd59dVXw7F77713mC9durRTj9mkqIkm0LNnz0S23XbbhWPTXrfDhw9PZN/73vfCsQcffHDpk1O8WvXJJ58Mx0YrVaV4lfWjjz4ajr3qqqvC/PXXXw/zdevWhXmKsCY4sgQAAJCBZgkAACADzRIAAEAGmiUAAIAMNEsAAAAZurLdCRrEAQcckMhuuummcGyPHvFf+dy5c8P8hhtuSGQrV64Mx65atSptimgBaStr+/TpE+bPP/98mD/11FOJbJtttgnHpq0I2mmnnRJZ7969w7FDhgwJ8xZZDYcG0r179zC/+OKLE9lll13WqfuI8mjVqCQ988wzYR79PpCke++9N5EtWLAgHJu2anbUqOSizFtvvTUcO2zYsDA/5phjwryTq+FCHFkCAADIQLMEAACQgWYJAAAgA80SAABABk7wbiJpW5g89thjiWz58uXh2LRtTU444YQwTzsJF1hf2gneZ555ZpinnXAdbW2SdrJ12sms0XYIJ554Yjg27SRXoNbSFhtceeWViSxtG6m0uorGz5kzJxz75S9/Ocz//Oc/h3lnbLnllmF+3333JbJBgwaFY6+44oowT/v9VgkcWQIAAMhAswQAAJCBZgkAACADzRIAAEAGmiUAAIAMG1wNZ2YTJB0taaG7717IBkm6XdJwSXMkneju71Vvmq1lq622CvPHH388zD/44INE1qtXr3Bs2uXjX3jhhRJnB2qic1avXt2pvBLbjPTs2TORpa2s+dznPhfms2fP7vI8WgU1UV0rVqxIZBtvvHE4Nm3bqa9//euJ7Mc//nHXJlYwYMCARHbQQQeFY6dMmRLmb7/9diJLW9V95513hnnayta0lbqdUcqRpYmSxqyXXSrpEXcfIemRwtdAq5goagLoaKKoCeTYBpsld39c0uL14mMkTSp8PknSsZWdFtC4qAmgGDWBvCv3opSD3X2+JLn7fDOLrzIlyczGShpb5uMAzYKaAIpRE8iNql/B293bJLVJkpl1/Y1DoMlRE0AxagKNrtzVcAvMbIgkFT4urNyUgKZETQDFqAnkRrlHlu6RdKakqwof767YjFpMdPb+3Llzw7Fpq4eilWzjxo0Lx/7pT3/qxOzQCdREA9lss80SWdpKmYUL+R1eJdREJ11yySVhPnPmzESWtlfoOeecE+ZPPPFEIotWsUnSzjvvHOZpq9Oildpp9522p92zzz6byNJWvUUrwKttg0eWzOw2SVMlfdzM5pnZOWp/8R9hZi9JOqLwNdASqAmgGDWBvNvgkSV3PznlW4dXeC5AU6AmgGLUBPKOK3gDAABkoFkCAADIQLMEAACQoerXWUK7nXbaKcynTZuWyNL2dVu5cmWYH3zwwYksbeUckCfbbLNNmB9yyCGJLK1+7r///orOCSjXsGHDwvyTn/xkIttoo43CsV/60pfC/LXXXktkJ58cn2p26qmnhvmQIUPCfOrUqYnsnnvuCcem7f0Y7Rm3du3acGw9cGQJAAAgA80SAABABpolAACADDRLAAAAGTjBu8I+//nPh/mNN94Y5mmXhI+knfgdXWo+7VL47vEelWk50MguuuiiMN90000TWVptpm3hAFRL2tY7d98d7whz3HHHlXzf0eIGSTrppJMS2cUXXxyOvfrqq8O8e/fuYR79/kg7ObtZf9dwZAkAACADzRIAAEAGmiUAAIAMNEsAAAAZaJYAAAAysBquBNEKgBEjRoRjJ06cGOZ9+vTp8jzStmvYb7/9Etmf/vSncOzxxx8f5vPnzy9/YkCVpW3tsGzZsjCPajZtmwW2BkKt7b///mH+5JNPhvlHH32UyHr37h2O/elPfxrm3/zmNxPZmjVr0qYYWrduXafG5wlHlgAAADLQLAEAAGSgWQIAAMhAswQAAJBhg82SmU0ws4Vm9nyH7HIze9PMni7cjqruNIHGQU0AxagJ5F0pq+EmSvqJpJ+vl//I3X9Q8Rk1oE9/+tOJ7Le//W04Nm3vnFdeeSXMo1V1aXvn9OzZM8yj8fvuu2849pxzzgnzSZMmhfkbb7wR5i1uolq8Jqpp8ODBiew///M/w7Hnnntuyff7L//yL2H+hz/8oeT7QKqJoiZKNmPGjDAfOnRomEcroXv0iH99p9XE4sWLE9m3vvWttCliPRs8suTuj0tK/pSBFkVNAMWoCeRdV85ZusDMni0cfh2YNsjMxprZdDOb3oXHApoBNQEUoyaQC+U2SzdK2kHSSEnzJf0wbaC7t7n7KHcfVeZjAc2AmgCKURPIjbKaJXdf4O5r3X2dpJslja7stIDmQk0AxagJ5ElZ252Y2RB3//v+GMdJej5rfLPYddddwzw6+TntRO5Vq1aF+eabb17yPNauXRvmt912W5g/9dRTieyHP4z/E3fFFVeE+ejR8b9j0fYonb1EfivIa01U0zbbbBPmjz32WCJLO/HVzEp+vNdeey3MW3kLh2qiJqRu3eLjEccdd1yYX3fddWG+fPnyRNa/f/9OPeYOO+wQ5ijNBpslM7tN0qGSNjezeZIuk3SomY2U5JLmSDqvelMEGgs1ARSjJpB3G2yW3P3kIL6lCnMBmgI1ARSjJpB3XMEbAAAgA80SAABABpolAACADGWthmt2Bx10UJj/7Gc/C/MhQ4Ykspdeeikce80114T5X/7ylzB/4oknElnaFiNnnnlmmG+88caJ7KKLLgrHbrvttmGetn0LK4VQLfPmzQvzQw45JJH95je/CcfuvffeJT/eCy+8UPJYIG1VWdp2VFtttVUia2trC8eOGTMmzN95550w//jHP57I9txzz3Ds1KlTw3y77bYLc5SGI0sAAAAZaJYAAAAy0CwBAABkoFkCAADIQLMEAACQoSVXw51//vlhvtNOO5V8H7NmzQrziRMnhnnaCoply5Ylsj/+8Y/h2B494r+uXXbZJZGl7RuUtj9W2sqk6DHT9r8DKuHNN99MZF//+tfDsQ8++GCYR6s4017jwLBhwxJZnz59wrHvvfdemJ922mmJbN999w3H/u1vfwvzvfbaK8yj/TjTxqZJ+52A0nBkCQAAIAPNEgAAQAaaJQAAgAw0SwAAABlolgAAADLkfjVc3759E9lxxx3X5fv9xje+EearV68O87SVbPPnz09kafvIpa3AGzBgQCJL29fopz/9aZg/9NBDYc7KNzSCZ555Jsw/+uijMO/evXvJ9wFEq5jT9godNGhQmH/1q19NZLfffns49vLLLw/ztWvXhvlGG22UyG688cZwbNrK66eeeirMURqOLAEAAGSgWQIAAMhAswQAAJCBZgkAACDDBk/wNrNhkn4uaStJ6yS1ufv1ZjZI0u2ShkuaI+lEd4+vA19H0QmgaSe67bfffmFuZols0qRJ4dh/+7d/C/O0E64vvvjiRJa2ZcrWW28d5u+++24iu+KKK8KxN998c5hzInfpmr0mmlHaVkTRia9SXBMrVqyo6JzwD81eE0uXLk1ke+yxRzj2ggsuCPPtt98+kS1atCgcG/1OkaRbbrklzE855ZSS7+PYY48N89/85jdhjtKUcmRpjaRx7r6LpAMknW9mu0q6VNIj7j5C0iOFr4FWQE0AxagJ5NoGmyV3n+/uMwufL5M0S9JQScdI+vvhlUmSjq3SHIGGQk0AxagJ5F2nrrNkZsMl7S1pmqTB7j5fai8UM9sy5c+MlTS2i/MEGhI1ARSjJpBHJTdLZtZP0h2SLnL3pWnvl67P3dsktRXuI75aFtCEqAmgGDWBvCppNZyZ9VR7Adzq7ncW4gVmNqTw/SGSFlZnikDjoSaAYtQE8qyU1XAm6RZJs9z92g7fukfSmZKuKny8uyoz7KLo8vGHHHJIOHb06NFhftZZZyWyMWPGhGOffPLJMP/ggw/C/Lnnnktk1157bTAyfUuSt956K5EtWbIkHLtu3bowR+mavSaaUc+ePcN8zZo1YT516tRqTgfraZaaGDduXJgfffTRieyoo44Kx1544YVhHq18Szuy9vjjj4f5gQceGObR/YwfPz4ce88994R52jYoKE0pb8MdKOl0Sc+Z2dOFbLzaX/xTzOwcSa9LOqEqMwQaDzUBFKMmkGsbbJbc/Y+S0t54Pryy0wEaHzUBFKMmkHdcwRsAACADzRIAAEAGmiUAAIAMnbooZUUesEfyIdNWtFRL2oqwP//5z53KAdTGzJkzwzxt1WfaHohobfvuu2+YR7+X0lx33XVhPnfu3ER2/fXXh2NHjBgR5mkr1pYvX57I3njjjU7dB7qGI0sAAAAZaJYAAAAy0CwBAABkoFkCAADIUPMTvGt9MjeA5rdq1aownzZtWpgPHTq0mtNBg0vbZuTcc88N8yOPPDKRbbbZZuHYjTbaKMx/97vfJbLOnmx90UUXhfmUKVMS2dtvv92p+0bXcGQJAAAgA80SAABABpolAACADDRLAAAAGWiWAAAAMtR8NRwAdFba6qZdd901zPv165fI2trawrFsD5E/aX+nK1asCPN99tknkf3iF78Ix44cOTLMe/XqlciOO+64cOycOXPC/MUXXwxzXqP1x5ElAACADDRLAAAAGWiWAAAAMtAsAQAAZKBZAgAAyLDB1XBmNkzSzyVtJWmdpDZ3v97MLpd0rqR3CkPHu3tycxwgZ6iJ2kvbG27q1KlhfsABBySy7t27h2PZr7Lrmr0mXn/99UR2yCGHhGO7dYuPMaxbt66ic0JjKeXSAWskjXP3mWa2iaQZZvZQ4Xs/cvcfVG96QEOiJoBi1ARybYPNkrvPlzS/8PkyM5sliS290bKoCaAYNYG869Q5S2Y2XNLekqYVogvM7Fkzm2BmA1P+zFgzm25m07s2VaDxUBNAMWoCeVRys2Rm/STdIekid18q6UZJO0gaqfb/Ufww+nPu3ubuo9x9VNenCzQOagIoRk0gr0pqlsysp9oL4FZ3v1OS3H2Bu69193WSbpY0unrTBBoLNQEUoyaQZ6WshjNJt0ia5e7XdsiHFN6nlqTjJD1fnSkCjYWaqL21a9eG+emnn17jmSDSSjXBqrfWVMpquAMlnS7pOTN7upCNl3SymY2U5JLmSDqvCvMDGhE1ARSjJpBrVsvdjM2MrZNRTzMa7ZwIagJ1Rk0AxcKa4AreAAAAGWiWAAAAMtAsAQAAZKBZAgAAyECzBAAAkIFmCQAAIAPNEgAAQAaaJQAAgAylXMG7khZJmlv4fPPC13nGc2ws29Z7AgFqIn+a6TlSE/XHc2wsYU3U9AreRQ9sNr3RrhxbaTxHdEYr/Cx5juiMVvhZ8hybA2/DAQAAZKBZAgAAyFDPZqmtjo9dKzxHdEYr/Cx5juiMVvhZ8hybQN3OWQIAAGgGvA0HAACQgWYJAAAgQ82bJTMbY2YvmtnLZnZprR+/WsxsgpktNLPnO2SDzOwhM3up8HFgPefYFWY2zMx+b2azzOwFM7uwkOfmOdYLNdGcqInqoSaaU55roqbNkpl1l3SDpM9J2lXSyWa2ay3nUEUTJY1ZL7tU0iPuPkLSI4Wvm9UaSePcfRdJB0g6v/B3l6fnWHPURFO/XqiJKqAmmvr1ktuaqPWRpdGSXnb3V919laTJko6p8Ryqwt0fl7R4vfgYSZMKn0+SdGwt51RJ7j7f3WcWPl8maZakocrRc6wTaqJJURNVQ000qTzXRK2bpaGS3ujw9bxClleD3X2+1P4ikrRlnedTEWY2XNLekqYpp8+xhqiJHKAmKoqayIG81UStmyULMq5d0ETMrJ+kOyRd5O5L6z2fHKAmmhw1UXHURJPLY03UulmaJ2lYh6+3kfRWjedQSwvMbIgkFT4urPN8usTMeqq9AG519zsLca6eYx1QE02MmqgKaqKJ5bUmat0sPSVphJltZ2a9JH1R0j01nkMt3SPpzMLnZ0q6u45z6RIzM0m3SJrl7td2+FZunmOdUBNNipqoGmqiSeW5Jmp+BW8zO0rSdZK6S5rg7t+p6QSqxMxuk3SopM0lLZB0maRfS5oi6WOSXpd0gruvf3JfUzCzgyQ9Iek5SesK8Xi1vx+di+dYL9REc75eqInqoSaa8/WS55pguxMAAIAMXMEbAAAgA80SAABABpolAACADDRLAAAAGWiWAAAAMtAsAQAAZKBZAgAAyPD/A4xZj16qinHHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_gen = cond_gan.generator\n",
    "\n",
    "\n",
    "\n",
    "interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
    "interpolation_noise = tf.repeat(interpolation_noise, repeats=10)\n",
    "interpolation_noise = tf.reshape(interpolation_noise, (10, latent_dim))\n",
    "\n",
    "\n",
    "labels = tf.keras.utils.to_categorical(list(range(0,10)), num_classes)\n",
    "#labels = keras.utils.to_categorical(list([7]*10), num_classes)\n",
    "\n",
    "# Combine the noise and the labels and run inference with the generator.\n",
    "noise_and_labels = tf.concat([interpolation_noise, labels], 1)\n",
    "fake = trained_gen.predict([interpolation_noise,labels])\n",
    "\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(3,3)\n",
    "\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "\n",
    "for i in range(0,3):\n",
    "    for j in range(0,3):\n",
    "        ax[i,j].imshow(fake[i*3+j],cmap='gray')\n",
    "        ax[i,j].set_title(f\"label: {i*3+j}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "#save generator model\n",
    "\n",
    "trained_gen.save(f\"gan_models/trained_gen_{sample_count}.h5\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f1fa92065e83bf8b3f9b5096216ce92755ea229f7fd6780b8b3e0f199343520"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
